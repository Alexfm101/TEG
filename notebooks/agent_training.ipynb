{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4ada078",
   "metadata": {},
   "source": [
    "# Este entrenamiento prueba el algoritmo vpg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a94577",
   "metadata": {},
   "source": [
    "### Instalar mujoco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d05c100",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Include this at the top of your colab code\n",
    "import os\n",
    "if not os.path.exists('.mujoco_setup_complete'):\n",
    "  # Get the prereqs\n",
    "  !apt-get -qq update\n",
    "  !apt-get -qq install -y libosmesa6-dev libgl1-mesa-glx libglfw3 libgl1-mesa-dev libglew-dev patchelf\n",
    "  # Get Mujoco\n",
    "  !mkdir ~/.mujoco\n",
    "  !wget -q https://mujoco.org/download/mujoco210-linux-x86_64.tar.gz -O mujoco.tar.gz\n",
    "  !tar -zxf mujoco.tar.gz -C \"$HOME/.mujoco\"\n",
    "  !rm mujoco.tar.gz\n",
    "  # Add it to the actively loaded path and the bashrc path (these only do so much)\n",
    "  !echo 'export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$HOME/.mujoco/mujoco210/bin' >> ~/.bashrc \n",
    "  !echo 'export LD_PRELOAD=$LD_PRELOAD:/usr/lib/x86_64-linux-gnu/libGLEW.so' >> ~/.bashrc \n",
    "  # THE ANNOYING ONE, FORCE IT INTO LDCONFIG SO WE ACTUALLY GET ACCESS TO IT THIS SESSION\n",
    "  !echo \"/root/.mujoco/mujoco210/bin\" > /etc/ld.so.conf.d/mujoco_ld_lib_path.conf\n",
    "  !ldconfig\n",
    "  # Install Mujoco-py\n",
    "  !pip3 install -U 'mujoco-py<2.2,>=2.1'\n",
    "  # run once\n",
    "  !touch .mujoco_setup_complete\n",
    "\n",
    "try:\n",
    "  if _mujoco_run_once:\n",
    "    pass\n",
    "except NameError:\n",
    "  _mujoco_run_once = False\n",
    "if not _mujoco_run_once:\n",
    "  # Add it to the actively loaded path and the bashrc path (these only do so much)\n",
    "  try:\n",
    "    os.environ['LD_LIBRARY_PATH']=os.environ['LD_LIBRARY_PATH'] + ':/root/.mujoco/mujoco210/bin'\n",
    "  except KeyError:\n",
    "    os.environ['LD_LIBRARY_PATH']='/root/.mujoco/mujoco210/bin'\n",
    "  try:\n",
    "    os.environ['LD_PRELOAD']=os.environ['LD_PRELOAD'] + ':/usr/lib/x86_64-linux-gnu/libGLEW.so'\n",
    "  except KeyError:\n",
    "    os.environ['LD_PRELOAD']='/usr/lib/x86_64-linux-gnu/libGLEW.so'\n",
    "  # presetup so we don't see output on first env initialization\n",
    "  import mujoco_py\n",
    "  _mujoco_run_once = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1deef96c",
   "metadata": {},
   "source": [
    "### instalar librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e68025",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clonar TEG \n",
    "#!rm -r TEG/ esta funcion se usa en caso de tener que remover el proyecto\n",
    "!git clone https://github.com/Alexfm101/TEG.git\n",
    "!pip3 install -e TEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b26b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clonar spinning up\n",
    "!sudo apt-get update && sudo apt-get install libopenmpi-dev\n",
    "!git clone https://github.com/openai/spinningup.git\n",
    "!pip3 install -e spinningup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3007e6",
   "metadata": {},
   "source": [
    "### configurar librerias para servidor(opcional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e96b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTAR LA LIBRERIA AL SYS\n",
    "import sys\n",
    "sys.path.append('TEG')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a98453",
   "metadata": {},
   "source": [
    "### importar  librerias (probar desde aqui)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b79c6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from RobotEnv.envs.UR5_Env import UR5_EnvTest #acuerdate de agregar TEG para colab\n",
    "from spinningup.spinup import vpg_pytorch as vpg\n",
    "import numpy as np\n",
    "import torch\n",
    "import  torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.distributions.normal import Normal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b243a224",
   "metadata": {},
   "source": [
    "### configurar entrenamiento\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a135c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# crear actor y critico\n",
    "\n",
    "#perceptron multicapa MPL\n",
    "def mlp(sizes, activation, output_activation=nn.Identity):\n",
    "    layers = []\n",
    "    for j in range(len(sizes)-1):\n",
    "        action = activation if j < len(sizes)-2 else output_activation\n",
    "        layers += [nn.Linear(sizes[j], sizes[j+1]), action()]\n",
    "\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "# politica de control\n",
    "class Policy(nn.Module):\n",
    "    \"\"\" implementación de la politica inicial para acciones continuas\"\"\"\n",
    "    def __init__(self, obs_dim, act_dim, hidden_sizes, activation):\n",
    "        super().__init__()\n",
    "        log_std = -0.5 * np.ones(act_dim, dtype=np.float32)\n",
    "        self.log_std = torch.nn.Parameter(torch.as_tensor(log_std))\n",
    "        self.mu_net = mlp([obs_dim] + list(hidden_sizes) + [act_dim], activation)\n",
    "\n",
    "    def distribution(self, obs):\n",
    "        \"\"\" distribución gaussiana diagonal \"\"\"\n",
    "        mu = self.mu_net(obs)\n",
    "        std = torch.exp(self.log_std)\n",
    "        return Normal(mu, std)\n",
    "\n",
    "    def log_prob_from_distribution(self, pi, action):\n",
    "        return pi.loq_prob(action).sum(axis=-1) # explicar despues\n",
    "\n",
    "    def foward(self, obs,  action=None):\n",
    "        \"\"\"\n",
    "        produce una distribución de acciones para una observación dada y\n",
    "        opcionalmente computa el log likelihood para una acción dada bajo esas distribuciónes\n",
    "        \"\"\"\n",
    "        pi = self.distribution(obs)\n",
    "        logp_a = None\n",
    "        if action is not None:\n",
    "            logp_a = self.log_prob_from_distribution(pi, action)\n",
    "\n",
    "        return pi, logp_a\n",
    "\n",
    "# función valor\n",
    "class Value_function(nn.Module):\n",
    "\n",
    "    def __init__(self, obs_dim,hidden_sizes, activation):\n",
    "        super().__init__()\n",
    "        self.value_network = mlp([obs_dim] + list(hidden_sizes) + [1], activation)\n",
    "\n",
    "        def forward(self, obs):\n",
    "            return torch.squeeze(self.value_network(obs), -1) # para asegurar que v tiene la forma correct\n",
    "\n",
    "# actor critico\n",
    "class ActorCritic(nn.Module):\n",
    "    \n",
    "    def __init__(self, observation_space, action_space, \n",
    "                 hidden_sizes=(64,64), activation=nn.Tanh):\n",
    "        super().__init__()\n",
    "        \n",
    "        obs_dim = observation_space.shape[0]\n",
    "        act_dim = action_space.shape[0]\n",
    "\n",
    "        # crear actor o politica\n",
    "        self.pi = Policy(obs_dim, act_dim, (64,64), activation=nn.Tanh)\n",
    "    \n",
    "        # crear critico o función valor\n",
    "        self.v = Value_function(obs_dim, hidden_sizes=(64,64), activation=nn.Tanh)\n",
    "\n",
    "    def step(self, obs):\n",
    "        with torch.no_grad():\n",
    "            pi = self.pi.distribution(obs)\n",
    "            a = pi.sample()\n",
    "            logp_a = self.pi.log_prob_from_distribution(pi, a)\n",
    "            v = self.v(obs)\n",
    "        return a.numpy(), v.numpy(), logp_a.numpy()\n",
    "\n",
    "    def act(self, obs):\n",
    "        return self.step(obs)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f703f17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entrenar\n",
    "env = UR5_EnvTest(simulation_frames=10, torque_control= 0.01, distance_threshold=0.5, Gui=False)\n",
    "\n",
    "ac = ActorCritic(env.observation_space, env.action_space)\n",
    "\n",
    "vpg(env, actor_critic=ac, ac_kwargs=dict(), seed=0, steps_per_epoch=2000, \n",
    "    epochs=50, gamma=0.99, pi_lr=3e-4,vf_lr=1e-3, train_v_iters=80, \n",
    "    lam=0.97, max_ep_len=1000,logger_kwargs=dict(), save_freq=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc-autonumbering": true,
  "toc-showcode": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
